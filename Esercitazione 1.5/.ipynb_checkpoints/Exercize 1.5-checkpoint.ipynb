{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235ef10e-8b8e-48a1-9346-fca3cf2c235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a036e216-14b9-4bb9-bac0-8065d9c41b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(sentence):\n",
    "    return remove_stopwords(tokenize_sentence(remove_punctuation(sentence)))\n",
    "\n",
    "# Remove punctuation from a list of words\n",
    "def remove_punctuation(sentence):\n",
    "    return re.sub(r'[^\\w\\s]', '', sentence)\n",
    "\n",
    "# Remove stopwords from a list of words\n",
    "def remove_stopwords(words_list):\n",
    "    stopwords = open(\"stop_words_FULL.txt\", \"r\")\n",
    "    stopwords_list = []\n",
    "    for word in stopwords:\n",
    "        stopwords_list.append(word.replace('\\n', ''))\n",
    "    stopwords.close()\n",
    "    return [value.lower() for value in words_list if value.lower() not in stopwords_list]\n",
    "\n",
    "# Tokenize the input sentence and also lemmatize its words\n",
    "def tokenize_sentence(sentence):\n",
    "    words_list = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        if (tag[1][:2] == \"NN\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.NOUN))\n",
    "        elif (tag[1][:2] == \"VB\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.VERB))\n",
    "        elif (tag[1][:2] == \"RB\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.ADV))\n",
    "        elif (tag[1][:2] == \"JJ\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.ADJ))\n",
    "    return words_list\n",
    "\n",
    "def get_words(readCSV):\n",
    "    for row in readCSV: return row  # return row\n",
    "\n",
    "def get_signature(sense):\n",
    "    signature = []\n",
    "    for word in tokenize_sentence(sense.definition()):  # definition tokenization\n",
    "        signature.append(word)\n",
    "    for example in sense.examples():  # example tokenization\n",
    "        for word in tokenize_sentence(example):\n",
    "            # Merge definition and examples\n",
    "            signature.append(word)\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fd0bb5-8a3a-4a53-b602-cc7083224467",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENUS_NUMBER = 5  # the number of most important terms to extract for a concept.\n",
    "\n",
    "# takes the .csv definitions file as input and outputs a dictionary in which each word ('Courage', 'Paper', 'Apprehension', 'Sharpener') \n",
    "# is associated with a list of pre-processed definitions.\n",
    "\n",
    "# returns a dict with terms as keys and a list of words within  term's defitions as a value\n",
    "def get_definitions_words(csvfile):\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    words = get_words(readCSV)[1:] \n",
    "\n",
    "    definitions_words = dict()\n",
    "\n",
    "    for row in readCSV:\n",
    "        for index, definition in enumerate(row):\n",
    "            if definition:  # check the definition is empty\n",
    "                if index > 0:\n",
    "                    word = words[index - 1]\n",
    "                    if word not in definitions_words.keys():\n",
    "                        definitions_words[word] = pre_processing(definition)\n",
    "                    else:\n",
    "                        definitions_words[word].extend(pre_processing(definition))\n",
    "    return definitions_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1f8ce5-239a-4e14-86b2-3dee617961ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the list of the 10 most important (most frequent) terms that appear in the bag of words of the definitions of the concept expressed by the word concept_word.\n",
    "def get_genus_list(concept_word, definitions_word):\n",
    "    dict_Counter = dict (Counter(definitions_word))\n",
    "    bag_of_words_count = []\n",
    "    for key in dict_Counter.keys():\n",
    "        bag_of_words_count.append((key, dict_Counter[key]))\n",
    "\n",
    "    return sorted(bag_of_words_count, key=lambda x: x[1], reverse=True)[:GENUS_NUMBER] # takes only first 5 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8131b6c7-0c4d-4a18-a1e5-a8e91217434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each genus, get a possible candidate. so for each genus get a list of hyponyms of all synsets related to the term genus.\n",
    "\n",
    "# return the synset hyponym that comes closest to the definitions of the concept_word, \n",
    "# that is the one with the signature (gloss + examples) that does the most overlap with the definitions.\n",
    "def get_candidates(concept_word, genus_list, definitions_word):\n",
    "    bag_of_words_defs = set(definitions_word)\n",
    "    candidates = []\n",
    "    for genus in genus_list:\n",
    "        hyponym_list = []\n",
    "        for synset in wn.synsets(genus[0]): # Obtain synsets (only for nouns) of genus word, We can also consider \n",
    "            hyponym_list.extend(synset.hyponyms())\n",
    "        if len(hyponym_list) != 0:\n",
    "            candidate = hyponym_list[0]\n",
    "            max_overlap = 0\n",
    "            for hyponym in hyponym_list:\n",
    "                hyponym_signature = get_signature(hyponym)\n",
    "                overlap = len(list(set(hyponym_signature) & bag_of_words_defs))\n",
    "                if overlap > max_overlap:\n",
    "                    candidate = hyponym\n",
    "                    max_overlap = overlap\n",
    "            candidates.append(candidate)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9921a075-644a-4b33-b45a-111595a45b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Concept:  Courage\n",
      "\n",
      "Genus list (with frequency): \n",
      "[('ability', 18), ('fear', 17), ('face', 9), ('situation', 7), ('scar', 5)]\n",
      "\n",
      "Candidates:\n",
      "[Synset('physical_ability.n.01'), Synset('stage_fright.n.01'), Synset('take_the_bull_by_the_horns.v.01'), Synset('crowding.n.01'), Synset('keloid.n.01')]\n",
      "-----------------------\n",
      "Concept:  Paper\n",
      "\n",
      "Genus list (with frequency): \n",
      "[('material', 23), ('write', 18), ('cellulose', 7), ('wood', 6), ('tree', 5)]\n",
      "\n",
      "Candidates:\n",
      "[Synset('composite_material.n.01'), Synset('handwrite.v.01'), Synset('pulp.n.03'), Synset('balsa.n.01'), Synset('poon.n.02')]\n",
      "-----------------------\n",
      "Concept:  Apprehension\n",
      "\n",
      "Genus list (with frequency): \n",
      "[('fear', 10), ('anxiety', 10), ('feeling', 5), ('happen', 5), ('feel', 4)]\n",
      "\n",
      "Candidates:\n",
      "[Synset('apprehension.n.01'), Synset('panic.n.02'), Synset('glow.v.05'), Synset('concur.v.02'), Synset('glow.v.05')]\n",
      "-----------------------\n",
      "Concept:  Sharpener\n",
      "\n",
      "Genus list (with frequency): \n",
      "[('pencil', 25), ('sharpen', 17), ('tool', 16), ('object', 11), ('allow', 4)]\n",
      "\n",
      "Candidates:\n",
      "[Synset('lead_pencil.n.01'), Synset('edge.v.04'), Synset('drill.n.01'), Synset('commemorative.n.01'), Synset('pass.v.17')]\n"
     ]
    }
   ],
   "source": [
    "with open('definizioni.csv') as csvfile:\n",
    "        # Create a dict with terms as keys and a list of words within  term's defitions as a value\n",
    "\n",
    "        definitions_words = get_definitions_words(csvfile)\n",
    "        for key in definitions_words.keys():\n",
    "            print(\"-----------------------\")\n",
    "            print(\"Concept: \",key)\n",
    "            print()\n",
    "            print(\"Genus list (with frequency): \")\n",
    "            genus_list = get_genus_list(key, definitions_words[key])\n",
    "            print(genus_list)\n",
    "            print(\"\\nCandidates:\")\n",
    "            print(get_candidates(key, genus_list, definitions_words[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
