{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07bbbbb-d2c3-4083-93de-730792971862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9769658f-8fef-46de-bea5-aa221e62b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(sentence):\n",
    "    return remove_stopwords(tokenize_sentence(remove_punctuation(sentence)))\n",
    "\n",
    "# Remove punctuation from a list of words\n",
    "def remove_punctuation(sentence):\n",
    "    return re.sub(r'[^\\w\\s]', '', sentence)\n",
    "\n",
    "# Remove stopwords from a list of words\n",
    "def remove_stopwords(words_list):\n",
    "    stopwords = open(\"stop_words_FULL.txt\", \"r\")\n",
    "    stopwords_list = []\n",
    "    for word in stopwords:\n",
    "        stopwords_list.append(word.replace('\\n', ''))\n",
    "    stopwords.close()\n",
    "    return [value.lower() for value in words_list if value.lower() not in stopwords_list]\n",
    "\n",
    "# Tokenize the input sentence and also lemmatize its words\n",
    "def tokenize_sentence(sentence):\n",
    "    words_list = []\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    for tag in nltk.pos_tag(word_tokenize(sentence)):\n",
    "        if (tag[1][:2] == \"NN\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.NOUN))\n",
    "        elif (tag[1][:2] == \"VB\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.VERB))\n",
    "        elif (tag[1][:2] == \"RB\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.ADV))\n",
    "        elif (tag[1][:2] == \"JJ\"):\n",
    "            words_list.append(lmtzr.lemmatize(tag[0], pos=wn.ADJ))\n",
    "    return words_list\n",
    "\n",
    "def get_words(readCSV):\n",
    "    for row in readCSV: return row  # return row\n",
    "\n",
    "def get_signature(sense):\n",
    "    signature = []\n",
    "    for word in tokenize_sentence(sense.definition()):  # definition tokenization\n",
    "        signature.append(word)\n",
    "    for example in sense.examples():  # example tokenization\n",
    "        for word in tokenize_sentence(example):\n",
    "            # Merge definition and examples\n",
    "            signature.append(word)\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8624fb4-31eb-4814-bb6b-065c5c60e093",
   "metadata": {},
   "source": [
    "prende in input il file delle definizioni .csv\n",
    "e restituisce in output un dizionario in cui ad ogni\n",
    "parola ('Courage', 'Paper', 'Apprehension', 'Sharpener')\n",
    "Ã¨ associato un set di definizioni\n",
    "\n",
    "le definizioni prima di essere inserite nel dizionario\n",
    "vengono pre-processate.In definitiva avremo una lista di liste\n",
    "per parola in cui ogni lista rappresenta una definizione in forma di bag-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0953bfd0-6ec4-4a3e-9f40-54a7705a1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definitions_words(csvfile):\n",
    "    \"\"\"\n",
    "    :param csvfile: link to csv file\n",
    "    :return: a dictionary as {word: {definition1,...}}\n",
    "    \"\"\"\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # get list of words to analize\n",
    "    words = get_words(readCSV)[1:]\n",
    "\n",
    "    definitions_words = dict()\n",
    "\n",
    "    for row in readCSV:\n",
    "        for index, definition in enumerate(row):\n",
    "            # check if the definition is empty\n",
    "            if definition:  \n",
    "                if index > 0:\n",
    "                    word = words[index - 1]\n",
    "                    if word not in definitions_words.keys():\n",
    "                        definitions_words[word] = [pre_processing(definition)]\n",
    "                    else:\n",
    "                        definitions_words[word].append(pre_processing(definition))\n",
    "    return definitions_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1608d9f-4f73-477f-a796-37dcb7033e35",
   "metadata": {},
   "source": [
    "Calculate cosine similarity scores between word's definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ffc45e-3e5e-4984-a9bc-053b1db92739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(definitions_words):\n",
    "    results = dict()\n",
    "    for word in definitions_words.keys():\n",
    "        definitions = definitions_words[word]\n",
    "        results[word] = compute_average_cosine_similarity(definitions)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9cdcf9-f2f6-41eb-952d-0b3bd0419e1e",
   "metadata": {},
   "source": [
    "Calculate similarity between two vectors which correspond presence or absence of certain word (for each word in definition 1 and definition 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0d3362-a665-4e5a-bcec-88b746146f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(def1, def2):\n",
    "    \"\"\"\n",
    "    :param def1: text of definiton 1\n",
    "    :param def2: text of definiton 2\n",
    "    \"\"\"\n",
    "    vector_def1 = []\n",
    "    vector_def2 = []\n",
    "    \n",
    "    # Obtain a vector indicating precense or absence of all words\n",
    "    both_def = list(set(def1) | set(def2))\n",
    "    for word in both_def:\n",
    "        if word in def1:\n",
    "            vector_def1.append(1)\n",
    "        else:\n",
    "            vector_def1.append(0)\n",
    "        if word in def2:\n",
    "            vector_def2.append(1)\n",
    "        else:\n",
    "            vector_def2.append(0)\n",
    "\n",
    "    c = 0\n",
    "    for i in range(len(both_def)):\n",
    "        c += vector_def1[i] * vector_def2[i]\n",
    "    cosine_score = c / float((sum(vector_def1) * sum(vector_def2)) ** 0.5)\n",
    "    return cosine_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b967a24-9f4b-430f-ae3b-2cd076ccfa29",
   "metadata": {},
   "source": [
    "Compute average cosine similarity between all definitions of a concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be22aca-1a33-4f3b-9f88-ef686023f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_cosine_similarity(definitions):\n",
    "    \"\"\"\n",
    "    :param definitions : all definitions of a concept\n",
    "    :return: average cosine similarity\n",
    "    \"\"\"\n",
    "    average_similarity = 0\n",
    "    count = 0\n",
    "    for def1 in definitions:\n",
    "        for def2 in definitions:\n",
    "            if not def1 == def2:\n",
    "                average_similarity += cosine_similarity(def1, def2)\n",
    "                count += 1\n",
    "    return average_similarity / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00f5da8-0f2d-407d-9d57-41fccdac424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Courage': 0.21054727554969985, 'Paper': 0.29258850377799267, 'Apprehension': 0.0830330313557733, 'Sharpener': 0.3863878711824424}\n"
     ]
    }
   ],
   "source": [
    "with open('definizioni.csv') as csvfile:\n",
    "    definitions_words = get_definitions_words(csvfile)\n",
    "    results = compute_results(definitions_words)\n",
    "    print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
